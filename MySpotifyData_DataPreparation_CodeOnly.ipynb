{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Spotify Data - Data preparation\n",
    "\n",
    "Data sources: \n",
    "- personal data: https://skiley.net/ & http://sortyourmusic.playlistmachinery.com/index.html & data requested from the Spotify website \n",
    "- Kaggle: https://www.kaggle.com/rodolfofigueroa/spotify-12m-songs & https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Data requested from Spotify (15.02.2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File 1: Playlist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/Playlist1.json\"\n",
    "\n",
    "Spotify_Playlists = json.load(open(file1, \"r\", encoding=\"utf8\"))\n",
    "Spotify_Playlists\n",
    "\n",
    "# File includes information about each playlist - artist, track and album names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get playlist names\n",
    "\n",
    "playlist_names = []\n",
    "for index in range(len(Spotify_Playlists['playlists'])):\n",
    "    playlist_names.append(Spotify_Playlists['playlists'][index]['name'])\n",
    "    \n",
    "playlist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of personal playlists\n",
    "\n",
    "len(Spotify_Playlists['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of songs in each playlist\n",
    "\n",
    "songs=[]\n",
    "names=[]\n",
    "\n",
    "for item in Spotify_Playlists[\"playlists\"]:\n",
    "    songs.append(len(item[\"items\"]))\n",
    "    names.append(item[\"name\"])\n",
    "\n",
    "songs_df = pd.DataFrame([songs]).transpose()\n",
    "songs_df\n",
    "\n",
    "names_df = pd.DataFrame([names]).transpose()\n",
    "names_df\n",
    "\n",
    "playlists_songs = names_df.join(songs_df, how=\"left\", rsuffix = \"new\")\n",
    "playlists_songs.head()\n",
    "\n",
    "playlists_songs.rename(columns={\"0\": \"PlaylistName\", \"0new\": \"Songs\"}, inplace=True)\n",
    "playlists_songs.sort_values(by=[\"Songs\"], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv file for further analysis\n",
    "\n",
    "playlists_songs.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/songs_in_playlists.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File 2: Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/Inferences.json\"\n",
    "\n",
    "Spotify_Inferences = json.load(open(file2, \"r\", encoding=\"utf8\"))\n",
    "Spotify_Inferences\n",
    "\n",
    "# Inferences -> from https://support.spotify.com/uk/article/understanding-my-data/ :\n",
    "# \"We draw certain inferences about your interests and preferences based on your usage of the Spotify service and \n",
    "# using data obtained from our advertisers and other advertising partners. \n",
    "# This includes a list of market segments with which you are currently associated.  \n",
    "# Depending on your settings, this data may be used to serve interest-based advertising to you within the \n",
    "# Spotify service.\"\n",
    "\n",
    "# -> not useful for this analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File 3: Userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/Userdata.json\"\n",
    "\n",
    "Spotify_Userdata = json.load(open(file3, \"r\", encoding=\"utf8\"))\n",
    "Spotify_Userdata\n",
    "\n",
    "# CreationTime: 2017-03-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files 4-4B: Streaming History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4 = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/StreamingHistory0.json\"\n",
    "\n",
    "Spotify_StreamingHistory0 = json.load(open(file4, \"r\", encoding=\"utf8\"))\n",
    "Spotify_StreamingHistory0\n",
    "\n",
    "# Other files: StreamingHistory1 / StreamingHistory2\n",
    "\n",
    "# Information about streamings -> \n",
    "# \"endTime\": Date and time of when the stream ended\n",
    "# \"msPlayed\": Stands for how many mili-seconds the track was listened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(Spotify_StreamingHistory0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving StreamTime and ArtistName to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save StreamTime as a list\n",
    "\n",
    "StreamTime0 = []\n",
    "for index in range(len(Spotify_StreamingHistory0)):\n",
    "    StreamTime0.append(Spotify_StreamingHistory0[index]['endTime'])\n",
    "    \n",
    "len(StreamTime0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ArtistName as a list\n",
    "\n",
    "ArtistName0 = []\n",
    "for index in range(len(Spotify_StreamingHistory0)):\n",
    "    ArtistName0.append(Spotify_StreamingHistory0[index]['artistName'])\n",
    "    \n",
    "ArtistName0\n",
    "len(ArtistName0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4A = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/StreamingHistory1.json\"\n",
    "\n",
    "Spotify_StreamingHistory1 = json.load(open(file4A, \"r\", encoding=\"utf8\"))\n",
    "Spotify_StreamingHistory1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamTime1 = []\n",
    "for index in range(len(Spotify_StreamingHistory1)):\n",
    "    StreamTime1.append(Spotify_StreamingHistory1[index]['endTime'])\n",
    "    \n",
    "StreamTime1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArtistName1 = []\n",
    "for index in range(len(Spotify_StreamingHistory1)):\n",
    "    ArtistName1.append(Spotify_StreamingHistory1[index]['artistName'])\n",
    "    \n",
    "ArtistName1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4B = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/StreamingHistory2.json\"\n",
    "\n",
    "Spotify_StreamingHistory2 = json.load(open(file4B, \"r\", encoding=\"utf8\"))\n",
    "Spotify_StreamingHistory2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamTime2 = []\n",
    "for index in range(len(Spotify_StreamingHistory2)):\n",
    "    StreamTime2.append(Spotify_StreamingHistory2[index]['endTime'])\n",
    "    \n",
    "StreamTime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArtistName2 = []\n",
    "for index in range(len(Spotify_StreamingHistory2)):\n",
    "    ArtistName2.append(Spotify_StreamingHistory2[index]['artistName'])\n",
    "    \n",
    "ArtistName2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect all lists (StreamTime)\n",
    "\n",
    "#len(StreamTime0) # 10000\n",
    "#len(StreamTime1) # 10000\n",
    "#len(StreamTime2) # 7988\n",
    "\n",
    "StreamTime = StreamTime0 + StreamTime1 + StreamTime2\n",
    "len(StreamTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect all lists (ArtistName)\n",
    "\n",
    "# StreamTime0.extend(StreamTime1)\n",
    "\n",
    "#len(ArtistName0) # 10000\n",
    "#len(ArtistName1) # 10000\n",
    "#len(ArtistName2) # 7988\n",
    "\n",
    "ArtistNames = ArtistName0 + ArtistName1 + ArtistName2\n",
    "len(ArtistNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into DataFrame (StreamTime)\n",
    "\n",
    "StreamTime_df = pd.DataFrame(StreamTime)\n",
    "StreamTime_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into DataFrame (StreamTime)\n",
    "\n",
    "ArtistNames_df = pd.DataFrame(ArtistNames)\n",
    "ArtistNames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both DataFrames\n",
    "\n",
    "ArtistNames_df.reset_index(inplace=True)\n",
    "StreamTime_df.reset_index(inplace=True)\n",
    "StreamTime_ArtistNames = ArtistNames_df.merge(StreamTime_df, on=\"index\")\n",
    "StreamTime_ArtistNames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "StreamTime_ArtistNames.rename(columns={\"0_x\":\"ArtistNames\", \"0_y\":\"StreamTime\"}, inplace=True)\n",
    "StreamTime_ArtistNames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamTime_ArtistNames.drop(columns=[\"index\"], inplace=True)\n",
    "StreamTime_ArtistNames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv-file\n",
    "\n",
    "StreamTime_ArtistNames.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/StreamTime_ArtistNames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File 5: SearchQueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file5 = \"C:/Users/Agnieszka/Downloads/Datasets/Music/my_spotify_data/MyData/SearchQueries.json\"\n",
    "\n",
    "Spotify_SearchQueries = json.load(open(file5, \"r\", encoding=\"utf8\"))\n",
    "Spotify_SearchQueries\n",
    "\n",
    "# A list of searches made : search time / device/platform used / search text / list of Uniform Resource Identifiers (URI) of the search results the user interacted with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Data from skiley.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one file to see the available features\n",
    "\n",
    "test = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Silkey_MySpotify/AfroHouse.csv\")\n",
    "test.head()\n",
    "\n",
    "# Important: 'trackName' / 'artistName' / 'secondaryArtistsNames' /'trackDuration' / 'addedAt' (??) /\n",
    "# \"isLocal\" - \"stream\" vs. \"local\" / 'trackPopularity' / 'artistPopularity' / 'artistFollowers' / 'artistGenres' /\n",
    "# 'albumRecordLabel' / 'albumReleaseDate'\n",
    "\n",
    "# not important: 'albumName'/ \"trackNumber\" / \"addedBy\" / 'albumArtistsNames' /'trackUrl'/ \n",
    "# 'artistUrl' / 'albumUrl'/ 'trackIsrc' (International Standard Recording Code)/ 'albumUpc' (Universal Product Code) / \n",
    "# 'albumType' / 'albumPopularity'\n",
    "\n",
    "# artistPopularity: The popularity of the artist. The value will be between 0 and 100, \n",
    "# with 100 being the most popular. The artist’s popularity is calculated from the popularity of all the artist’s tracks.\n",
    "# https://developer.spotify.com/documentation/web-api/reference/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with all playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with all playlists\n",
    "\n",
    "import glob\n",
    "df_Silkey = pd.concat([pd.read_csv(f) for f in glob.glob(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Silkey_MySpotify/\" + \"*.csv\")], ignore_index=True)\n",
    "len(df_Silkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Data from sortyourmusic.playlistmachinery.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_excel(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic_20210305.xlsx\", sheet_name=\"AfroHouse\")\n",
    "test2.head()\n",
    "\n",
    "\n",
    "# Double information: Title / Artist / Release / Length / Pop. / \n",
    "# not important: RND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check files in the directory\n",
    "\n",
    "#import os\n",
    "#files = os.listdir(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic/\")\n",
    "#files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with all playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with all playlists\n",
    "\n",
    "df_SortYourMusic = pd.concat([pd.read_excel(f) for f in glob.glob(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic/\" + \"*.xlsx\")], ignore_index=True)\n",
    "len(df_SortYourMusic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets for further analysis and ML models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Dataset with data from all playlists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Silkey.reset_index(inplace=True)\n",
    "df_Silkey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SortYourMusic.reset_index(inplace=True)\n",
    "df_SortYourMusic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both DataFrames (df_Silkey & df_SortYourMusic)\n",
    "\n",
    "All_songs = df_Silkey.merge(df_SortYourMusic, on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_songs[[\"trackName\", \"Title\"]].iloc[4000:4040]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "\n",
    "All_songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "# df_SortYourMusic: \n",
    "# Title / Artist / Release / Length / Pop. <- Double information & not important: RND\n",
    "# df_Silkey \n",
    "# # not important: 'albumName'/ \"trackNumber\" / \"addedBy\" / 'albumArtistsNames' /'trackUrl'/ \n",
    "# 'artistUrl' / 'albumUrl'/ 'trackIsrc' (International Standard Recording Code)/ 'albumUpc' (Universal Product Code) / \n",
    "# 'albumType' / 'albumPopularity'\n",
    "\n",
    "\n",
    "All_songs_cleaned1 = All_songs.drop(columns=[\"albumName\", \n",
    "                            \"trackNumber\",\n",
    "                            \"addedBy\",\n",
    "                            \"albumArtistsNames\",\n",
    "                            \"trackUrl\",\n",
    "                            \"artistUrl\",\n",
    "                            \"albumUrl\",\n",
    "                            \"trackIsrc\",\n",
    "                            \"albumUpc\",\n",
    "                            \"albumType\",\n",
    "                            \"albumPopularity\",\n",
    "                            'Title', \n",
    "                            'Artist', \n",
    "                            'Release', \n",
    "                            \"Length\", \n",
    "                            \"Pop.\",\n",
    "                            \"RND\",\n",
    "                            '#',          \n",
    "                           ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(All_songs_cleaned1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any duplicates\n",
    "Duplicates = All_songs_cleaned1[[\"artistName\", \"trackName\", \"index\"]].groupby([\"trackName\", \"artistName\"]).count().sort_values(\"index\", ascending=False)\n",
    "Duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate items\n",
    "#Duplicates2 = Duplicates[Duplicates[\"index\"] > 1]\n",
    "#len(Duplicates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single items\n",
    "#Duplicates3 = Duplicates[Duplicates[\"index\"] == 1]\n",
    "#len(Duplicates3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned2 = All_songs_cleaned1.drop_duplicates(subset=[\"artistName\", \"trackName\"], keep=\"first\")\n",
    "All_songs_cleaned2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows without \"artistName\" -> I can do that because all rows without an artist name are local files\n",
    "All_songs_cleaned2.dropna(axis=0, subset=[\"artistName\"], inplace=True)\n",
    "All_songs_cleaned2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values in BPM, Energy etc. columns -> There still might be local data in the dataset\n",
    "All_songs_cleaned2_test2 = All_songs_cleaned2[All_songs_cleaned2[\"BPM\"].isna() == True]\n",
    "All_songs_cleaned2_test2.head()                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all local data -> there is no information about this data that can be used for further analysis\n",
    "All_songs_cleaned3 = All_songs_cleaned2[All_songs_cleaned2[\"isLocal\"]==\"stream\"]\n",
    "All_songs_cleaned3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are still missing values in \"SecondaryArtistNames\" and \"artistGenres\" \n",
    "# -> These columns remain in the dataset for the EDA; they will be removed for modeling (machine learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split \"artistGenres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"artistGenres\"\n",
    "All_songs_clean3[\"artistGenres\"][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset without NaNs in \"ArtistGenres\"\n",
    "\n",
    "#All_songs_clean_Genre = All_songs_clean3.dropna(axis=0, subset=[\"artistGenres\"])\n",
    "#All_songs_clean_Genre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned3_Genres = All_songs_cleaned3[\"artistGenres\"].str.split(\",\", expand=True)\n",
    "print(len(All_songs_cleaned3_Genres))\n",
    "All_songs_cleaned3_Genres.head()\n",
    "# up to 16 different genres for some songs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce genres \n",
    "All_songs_cleaned3_Genres_reduced = All_songs_cleaned3_Genres.iloc[:,0:5]\n",
    "All_songs_cleaned3_Genres_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned3_Genres_reduced.rename(columns={0:\"Genre1\",\n",
    "                                                    1:\"Genre2\",\n",
    "                                                    2:\"Genre3\",\n",
    "                                                    3:\"Genre4\",\n",
    "                                                    4:\"Genre5\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned3_Genres_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Genre-DataFrame with previous cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned3_Genres_reduced.reset_index(inplace=True)\n",
    "All_songs_cleaned4 = All_songs_cleaned3.merge(All_songs_cleaned3_Genres_reduced, on=\"index\")\n",
    "All_songs_cleaned4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4.drop(columns=[\"isLocal\", \"artistGenres\"], inplace=True)\n",
    "All_songs_cleaned4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert \"object\" into \"datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to datetime: \n",
    "# - TrackDuration [3], \n",
    "# - addedAt [4] -> Format: 2018-08-19T20:44:37Z, \n",
    "# - albumReleaseDate [10] -> 2015-07-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All_songs_cleaned4[\"trackDuration\"] = pd.to_datetime(All_songs_cleaned4[\"trackDuration\"], format=\"%H:%M:%S\") # Datetime\n",
    "All_songs_cleaned4[\"trackDuration\"] = pd.to_datetime(All_songs_cleaned4[\"trackDuration\"]).dt.time #string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "All_songs_cleaned4[\"trackDuration\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4[\"addedAt\"] = pd.to_datetime(All_songs_cleaned4[\"addedAt\"]).dt.tz_convert(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4[\"addedAt\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4[\"albumReleaseDate\"] = pd.to_datetime(All_songs_cleaned4[\"albumReleaseDate\"], yearfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "All_songs_cleaned4[\"albumReleaseDate\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save DataFrame to csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_songs_cleaned4.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/AllSongsCleaned_EDA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Dataset for machine learning models** (includes all songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with songs that I like and do not like. \n",
    "Songs that I like come from my personal playlists, songs I do not like I will take from a Kaggle dataset. I will select them based on the genre. I will create an extra column \"like\" for the classification (modeling) in each dataset -> like = 1 & like = 0 (like/ do not like). In the last step I will combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) My data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySpotify_cleaned = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/AllSongsCleaned_EDA.csv\")\n",
    "MySpotify_cleaned.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "MySpotify_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that are not relevant for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySpotify_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySpotify_cleaned_modeling = MySpotify_cleaned[[\"artistName\", \"trackPopularity\", \"BPM\", \"Energy\", \"Dance\", \"Loud\",\n",
    "                                              \"Valence\", \"Acoustic\", \"Genre1\"]]\n",
    "MySpotify_cleaned_modeling.head()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"like\" column for classification (modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySpotify_cleaned_modeling[\"like\"] = 1\n",
    "MySpotify_cleaned_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Spotify_Dataset1/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Kaggle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select songs that I probably wouldn't like based on the genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split genre column\n",
    "\n",
    "Kaggle_Genres = Kaggle[\"genres\"].str.split(\",\", expand=True)\n",
    "# output: 20 columns - only the first one remains\n",
    "Kaggle_Genres1 = pd.DataFrame(Kaggle_Genres[0])\n",
    "Kaggle_Genres1.head()\n",
    "\n",
    "#Kaggle_Genres = pd.DataFrame(Kaggle_Genres[0].to_list()) -> is not a list; \"[]\" -> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the genre column with only one genre to the initial dataset\n",
    "Kaggle1 = pd.concat([Kaggle, Kaggle_Genres1], axis=1)\n",
    "Kaggle1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select ca. 3461 random songs based on genres I don't like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kaggle_random():\n",
    "    # genre that contains: \"...\"\n",
    "    Kaggle_pop = Kaggle1[Kaggle1[0].str.contains(\"pop\")]\n",
    "    # Take n samples from this genre\n",
    "    Kaggle_pop_random = Kaggle_pop.sample(n=1770) # 1500 + ca. 200 duplicates\n",
    "    \n",
    "    Kaggle_techno = Kaggle1[Kaggle1[\"genres\"].str.contains(\"techno\")]\n",
    "    Kaggle_techno_random = Kaggle_techno.sample(n=250)\n",
    "    \n",
    "    Kaggle_acid = Kaggle1[Kaggle1[\"genres\"].str.contains(\"acid\")]\n",
    "    Kaggle_acid_random = Kaggle_acid.sample(n=31)\n",
    "    \n",
    "    Kaggle_trance = Kaggle1[Kaggle1[0].str.contains(\"trance\")]\n",
    "    Kaggle_trance_random = Kaggle_trance.sample(n=250)\n",
    "    \n",
    "    Kaggle_death = Kaggle1[Kaggle1[\"genres\"].str.contains(\"death\")]\n",
    "    Kaggle_death_random = Kaggle_death.sample(n=50)\n",
    "    \n",
    "    Kaggle_punk = Kaggle1[Kaggle1[0].str.contains(\"punk\")]\n",
    "    Kaggle_punk_random = Kaggle_punk.sample(n=200)\n",
    "    \n",
    "    Kaggle_country = Kaggle1[Kaggle1[0].str.contains(\"country\")]\n",
    "    Kaggle_country_random = Kaggle_country.sample(n=400)\n",
    "    \n",
    "    Kaggle_emo = Kaggle1[Kaggle1[0].str.contains(\"emo\")]\n",
    "    Kaggle_emo_random = Kaggle_emo.sample(n=100)\n",
    "    \n",
    "    Kaggle_chinese = Kaggle1[Kaggle1[\"genres\"].str.contains(\"chinese\")] #\n",
    "    Kaggle_chinese_random = Kaggle_chinese.sample(n=50)\n",
    "    \n",
    "    Kaggle_psy = Kaggle1[Kaggle1[0].str.contains(\"psy\")]\n",
    "    Kaggle_psy_random = Kaggle_psy.sample(n=80)\n",
    "    \n",
    "    Kaggle_german = Kaggle1[Kaggle1[\"genres\"].str.contains(\"german\")] # \n",
    "    Kaggle_german_random = Kaggle_german.sample(n=150)\n",
    "    \n",
    "    Kaggle_edm = Kaggle1[Kaggle1[0].str.contains(\"edm\")]\n",
    "    Kaggle_edm_random = Kaggle_edm.sample(n=70)\n",
    "    \n",
    "    Kaggle_romantic = Kaggle1[Kaggle1[0].str.contains(\"romantic\")]\n",
    "    Kaggle_romantic_random = Kaggle_edm.sample(n=70)\n",
    "    \n",
    "    Kaggle_synth = Kaggle1[Kaggle1[\"genres\"].str.contains(\"synth\")] #\n",
    "    Kaggle_synth_random = Kaggle_synth.sample(n=200)\n",
    "      \n",
    "    Kaggle_dataset = pd.concat([Kaggle_pop_random, Kaggle_techno_random, Kaggle_acid_random,\n",
    "                                Kaggle_death_random, Kaggle_trance_random, Kaggle_punk_random, \n",
    "                                Kaggle_country_random, Kaggle_emo_random, Kaggle_chinese_random, \n",
    "                                Kaggle_psy_random, Kaggle_german_random, Kaggle_edm_random,\n",
    "                               Kaggle_romantic_random, Kaggle_synth_random, Kaggle_chinese_random], axis=0)\n",
    "    return Kaggle_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_dataset = Kaggle_random()\n",
    "len(Kaggle_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicates2A = Kaggle_test[\"artists\"].value_counts()\n",
    "#Duplicates2A.head(50)\n",
    "\n",
    "Kaggle_dataset_drop = Kaggle_dataset.drop_duplicates(keep=\"first\")\n",
    "len(Kaggle_dataset_drop)\n",
    "#3461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns to merge the dataset with \"MySpotify\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kaggle_dataset_drop.columns)\n",
    "print(MySpotify_cleaned_modeling.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_dataset_modeling = Kaggle_dataset_drop[[\"artists\", \"popularity\", \"tempo\", \"energy\", \"danceability\", \"loudness\",\n",
    "                                              \"valence\", \"acousticness\", 0]]\n",
    "Kaggle_dataset_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"like\" column for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_dataset_modeling[\"like\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kaggle_dataset_modeling.columns)\n",
    "print(MySpotify_cleaned_modeling.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySpotify_cleaned_modeling.rename(columns={\"artistName\": \"artists\",\n",
    "                                          \"trackPopularity\": \"popularity\",\n",
    "                                          \"Energy\":\"energy\",\n",
    "                                          \"Dance\":\"danceability\",\n",
    "                                          \"Loud\":\"loudness\",\n",
    "                                          \"Valence\":\"valence\",\n",
    "                                          \"Acoustic\": \"acousticness\",\n",
    "                                          \"Genre1\": \"genre\"}, inplace=True)\n",
    "\n",
    "Kaggle_dataset_modeling.rename(columns={\"tempo\":\"BPM\",\n",
    "                                        \"acousticnes\": \"acousticness\",\n",
    "                                       0:\"genre\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle_dataset_modeling.rename(columns={0:\"genre\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kaggle_dataset_modeling.columns)\n",
    "print(MySpotify_cleaned_modeling.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_modeling = pd.concat([MySpotify_cleaned_modeling, Kaggle_dataset_modeling])\n",
    "dataset_modeling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Kaggle_dataset_modeling) + len(MySpotify_cleaned_modeling))\n",
    "print(len(dataset_modeling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_modeling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_modeling.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/dataset_modeling_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Dataset for machine learning models** (includes songs recently played)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my playlists include very different genres and many of them I haven't been listening to for ages, I will create models based only on playlists I have been listening to more recently to check if this enhance the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_train():\n",
    "    \n",
    "    ## My Spotify data\n",
    "    \n",
    "    # Datasets Silkey.net\n",
    "    import glob\n",
    "    df_Silkey1 = pd.concat([pd.read_csv(f) for f in glob.glob(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Silkey_MySpotify/Recent/\" + \"*.csv\")], ignore_index=True)\n",
    "    #len(df_Silkey)\n",
    "    df_Silkey1.reset_index(inplace=True)\n",
    "    \n",
    "    \n",
    "    # Dataset SortYourMusic\n",
    "    df_SortYourMusic1 = pd.concat([pd.read_excel(f) for f in glob.glob(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic/Recent/\" + \"*.xlsx\")], ignore_index=True)\n",
    "    #len(df_SortYourMusic)\n",
    "    df_SortYourMusic1.reset_index(inplace=True)\n",
    "    \n",
    "    # Merge both datasets\n",
    "    All_songs = df_Silkey1.merge(df_SortYourMusic1, on=\"index\")\n",
    "    \n",
    "    # Select relevant features\n",
    "    All_songs_cleaned1 = All_songs[[\"artistName\", \"trackName\", \"trackPopularity\", \"BPM\", \"Energy\", \"Dance\", \"Loud\",\n",
    "                                    \"Valence\", \"Acoustic\",\"artistGenres\",\"isLocal\"]]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    All_songs_cleaned2 = All_songs_cleaned1.drop_duplicates(subset=[\"artistName\", \"trackName\"], keep=\"first\")\n",
    "    \n",
    "    # Drop NaN\n",
    "    # Remove all local data -> there is no information about this data that can be used for further analysis\n",
    "    All_songs_cleaned3 = All_songs_cleaned2[All_songs_cleaned2[\"isLocal\"]==\"stream\"]\n",
    "    \n",
    "    \n",
    "    # Split Genre column \n",
    "    All_songs_cleaned3_Genres = All_songs_cleaned3[\"artistGenres\"].str.split(\",\", expand=True)\n",
    "    # Leave only first column\n",
    "    All_songs_cleaned3_Genres_reduced = All_songs_cleaned3_Genres.iloc[:,0]\n",
    "    All_songs_cleaned3_Genres_reduced1 = pd.DataFrame(All_songs_cleaned3_Genres_reduced)\n",
    "    \n",
    "    # Rename column\n",
    "    All_songs_cleaned3_Genres_reduced1.rename(columns={0:\"Genre1\"}, inplace=True)\n",
    "    \n",
    "    # Merge \"Genre\"-DataFrame with the initial dataset\n",
    "    All_songs_cleaned3_Genres_reduced1.reset_index(inplace=True)\n",
    "    All_songs_cleaned3.reset_index(inplace=True)\n",
    "    All_songs_cleaned4 = All_songs_cleaned3.merge(All_songs_cleaned3_Genres_reduced1, on=\"index\")\n",
    "    \n",
    "    #Drop columns\n",
    "    All_songs_cleaned4.drop(columns=[\"isLocal\", \"artistGenres\", \"trackName\", \"index\"], inplace=True)\n",
    "    \n",
    "    #Add \"like\" column for classification (modeling)\n",
    "    All_songs_cleaned4[\"like\"] = 1\n",
    "    \n",
    "    # Rename columns\n",
    "    All_songs_cleaned4.rename(columns={\"artistName\": \"artists\",\n",
    "                                          \"trackPopularity\": \"popularity\",\n",
    "                                          \"Energy\":\"energy\",\n",
    "                                          \"Dance\":\"danceability\",\n",
    "                                          \"Loud\":\"loudness\",\n",
    "                                          \"Valence\":\"valence\",\n",
    "                                          \"Acoustic\": \"acousticness\",\n",
    "                                          \"Genre1\": \"genre\"}, inplace=True)\n",
    "    \n",
    "    ## Kaggle dataset\n",
    "    Kaggle_dataset = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Spotify_Dataset1/data_w_genres.csv\")\n",
    "    \n",
    "    # Split genre column\n",
    "    Kaggle_Genres = Kaggle_dataset[\"genres\"].str.split(\",\", expand=True)\n",
    "    # Select only first column (from 20!)\n",
    "    Kaggle_Genres1 = pd.DataFrame(Kaggle_Genres[0])\n",
    "    \n",
    "    # Add the genre column with only one genre to the initial dataset\n",
    "    Kaggle1 = pd.concat([Kaggle_dataset, Kaggle_Genres1], axis=1)\n",
    "    \n",
    "    # Select ca. 1762 (=len(All_songs_cleaned4)) random songs based on genres I don't like\n",
    "    # genre that contains: \"...\"\n",
    "    Kaggle_pop = Kaggle1[Kaggle1[0].str.contains(\"pop\")]\n",
    "    # Take n samples from this genre\n",
    "    Kaggle_pop_random = Kaggle_pop.sample(n=870) \n",
    "    \n",
    "    Kaggle_techno = Kaggle1[Kaggle1[\"genres\"].str.contains(\"techno\")]\n",
    "    Kaggle_techno_random = Kaggle_techno.sample(n=125)\n",
    "    \n",
    "    Kaggle_acid = Kaggle1[Kaggle1[\"genres\"].str.contains(\"acid\")]\n",
    "    Kaggle_acid_random = Kaggle_acid.sample(n=16)\n",
    "    \n",
    "    Kaggle_trance = Kaggle1[Kaggle1[0].str.contains(\"trance\")]\n",
    "    Kaggle_trance_random = Kaggle_trance.sample(n=125)\n",
    "    \n",
    "    Kaggle_death = Kaggle1[Kaggle1[\"genres\"].str.contains(\"death\")]\n",
    "    Kaggle_death_random = Kaggle_death.sample(n=25)\n",
    "    \n",
    "    Kaggle_punk = Kaggle1[Kaggle1[0].str.contains(\"punk\")]\n",
    "    Kaggle_punk_random = Kaggle_punk.sample(n=100)\n",
    "    \n",
    "    Kaggle_country = Kaggle1[Kaggle1[0].str.contains(\"country\")]\n",
    "    Kaggle_country_random = Kaggle_country.sample(n=200)\n",
    "    \n",
    "    Kaggle_emo = Kaggle1[Kaggle1[0].str.contains(\"emo\")]\n",
    "    Kaggle_emo_random = Kaggle_emo.sample(n=50)\n",
    "    \n",
    "    Kaggle_chinese = Kaggle1[Kaggle1[\"genres\"].str.contains(\"chinese\")] #\n",
    "    Kaggle_chinese_random = Kaggle_chinese.sample(n=25)\n",
    "    \n",
    "    Kaggle_psy = Kaggle1[Kaggle1[0].str.contains(\"psy\")]\n",
    "    Kaggle_psy_random = Kaggle_psy.sample(n=40)\n",
    "    \n",
    "    Kaggle_german = Kaggle1[Kaggle1[\"genres\"].str.contains(\"german\")] # \n",
    "    Kaggle_german_random = Kaggle_german.sample(n=75)\n",
    "    \n",
    "    Kaggle_edm = Kaggle1[Kaggle1[0].str.contains(\"edm\")]\n",
    "    Kaggle_edm_random = Kaggle_edm.sample(n=35)\n",
    "    \n",
    "    Kaggle_romantic = Kaggle1[Kaggle1[0].str.contains(\"romantic\")]\n",
    "    Kaggle_romantic_random = Kaggle_edm.sample(n=35)\n",
    "    \n",
    "    Kaggle_synth = Kaggle1[Kaggle1[\"genres\"].str.contains(\"synth\")] #\n",
    "    Kaggle_synth_random = Kaggle_synth.sample(n=100)\n",
    "    \n",
    "    \n",
    "    Kaggle_dataset = pd.concat([Kaggle_pop_random, Kaggle_techno_random, Kaggle_acid_random,\n",
    "                                Kaggle_death_random, Kaggle_trance_random, Kaggle_punk_random, \n",
    "                                Kaggle_country_random, Kaggle_emo_random, Kaggle_chinese_random, \n",
    "                                Kaggle_psy_random, Kaggle_german_random, Kaggle_edm_random,\n",
    "                               Kaggle_romantic_random, Kaggle_synth_random, Kaggle_chinese_random], axis=0)\n",
    "     \n",
    "    # Drop duplicates\n",
    "    Kaggle_dataset_drop1 = Kaggle_dataset.drop_duplicates(keep=\"first\")\n",
    "    \n",
    "    # Select relevant features\n",
    "    Kaggle_dataset_modeling = Kaggle_dataset_drop1[[\"artists\", \"popularity\", \"tempo\", \"energy\", \"danceability\", \"loudness\",\n",
    "                                              \"valence\", \"acousticness\", 0]]\n",
    "    \n",
    "    #Add \"like\" column for classification (modeling)\n",
    "    Kaggle_dataset_modeling[\"like\"] = 0\n",
    "    \n",
    "    # Rename columns\n",
    "    Kaggle_dataset_modeling.rename(columns={\"tempo\":\"BPM\",\n",
    "                                            \"acousticnes\": \"acousticness\",\n",
    "                                           0:\"genre\"}, inplace=True)\n",
    "    \n",
    "    #Concatenate both datasets\n",
    "    dataset_modeling2 = pd.concat([All_songs_cleaned4, Kaggle_dataset_modeling])\n",
    "    \n",
    "    return dataset_modeling2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_modeling_recent = preparation_train()\n",
    "print(len(Dataset_modeling_recent))\n",
    "Dataset_modeling_recent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_modeling_recent.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/dataset_modeling_recent.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Dataset for machine learning models** (test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = name of the playlist file (Check, Colors_AllShows, DiscoverWeekly_March1)\n",
    "\n",
    "def prepare_test(filename):\n",
    "    \n",
    "    # Load datasets\n",
    "    dataset_Silkey = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Silkey_MySpotify/PlaylistsForTesting/\" + filename + \".csv\")\n",
    "    dataset_SortYourMusic = dataset = pd.read_excel(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic/PlaylistsForTesting/\" + filename + \".xlsx\")\n",
    "    \n",
    "    # Merge both datasets\n",
    "    dataset_Silkey.reset_index(inplace=True)\n",
    "    dataset_SortYourMusic.reset_index(inplace=True)\n",
    "    \n",
    "    Test_songs = dataset_Silkey.merge(dataset_SortYourMusic, on=\"index\")\n",
    "    \n",
    "    # Select relevant features\n",
    "    Test_songs_cleaned1 = Test_songs[[\"artistName\", \"trackName\", \"trackPopularity\", \"BPM\", \"Energy\", \"Dance\", \"Loud\",\n",
    "                                    \"Valence\", \"Acoustic\",\"artistGenres\",\"isLocal\"]]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    Test_songs_cleaned2 = Test_songs_cleaned1.drop_duplicates(subset=[\"artistName\", \"trackName\"], keep=\"first\")\n",
    "    \n",
    "    # Drop NaN\n",
    "    # Remove all local data -> there is no information about this data that can be used for further analysis\n",
    "    Test_songs_cleaned3 = Test_songs_cleaned2[Test_songs_cleaned2[\"isLocal\"]==\"stream\"]\n",
    "    \n",
    "    \n",
    "    # Split Genre column \n",
    "    Test_songs_cleaned3_Genres = Test_songs_cleaned3[\"artistGenres\"].str.split(\",\", expand=True)\n",
    "    # Leave only first column\n",
    "    Test_songs_cleaned3_Genres_reduced = Test_songs_cleaned3_Genres.iloc[:,0]\n",
    "    Test_songs_cleaned3_Genres_reduced1 = pd.DataFrame(Test_songs_cleaned3_Genres_reduced)\n",
    "    \n",
    "    # Rename column\n",
    "    Test_songs_cleaned3_Genres_reduced1.rename(columns={0:\"Genre1\"}, inplace=True)\n",
    "    \n",
    "    # Merge \"Genre\"-DataFrame with the initial dataset\n",
    "    Test_songs_cleaned3_Genres_reduced1.reset_index(inplace=True)\n",
    "    Test_songs_cleaned3.reset_index(inplace=True)\n",
    "    Test_songs_cleaned4 = Test_songs_cleaned3.merge(Test_songs_cleaned3_Genres_reduced1, on=\"index\")\n",
    "    \n",
    "    #Drop columns\n",
    "    Test_songs_cleaned4.drop(columns=[\"isLocal\", \"artistGenres\", \"trackName\", \"index\"], inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    Test_songs_cleaned4.rename(columns={\"artistName\": \"artists\",\n",
    "                                          \"trackPopularity\": \"popularity\",\n",
    "                                          \"Energy\":\"energy\",\n",
    "                                          \"Dance\":\"danceability\",\n",
    "                                          \"Loud\":\"loudness\",\n",
    "                                          \"Valence\":\"valence\",\n",
    "                                          \"Acoustic\": \"acousticness\",\n",
    "                                          \"Genre1\": \"genre\"}, inplace=True)\n",
    "    \n",
    "    return Test_songs_cleaned4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) My \"Check\" playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Check = prepare_test(\"Check\")\n",
    "Test_set_Check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Check.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/testset_check.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) My \"Discover Weekly\" playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Weekly = prepare_test(\"DiscoverWeekly_March1\")\n",
    "Test_set_Weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Weekly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Weekly.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/testset_weekly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) \"Colors - All shows\" playlist (from Colors Studios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Colors = prepare_test(\"Colors_AllShows\")\n",
    "Test_set_Colors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Colors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_Colors.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/testset_colors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Datasets for EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA only for selected playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_EDA(filename):\n",
    "    \n",
    "    # Load datasets\n",
    "    dataset_Silkey = pd.read_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/Silkey_MySpotify/\" + filename + \".csv\")\n",
    "    dataset_SortYourMusic = dataset = pd.read_excel(\"C:/Users/Agnieszka/Downloads/Datasets/Music/SortYourMusic/\" + filename + \".xlsx\")\n",
    "    \n",
    "    # Merge both datasets\n",
    "    dataset_Silkey.reset_index(inplace=True)\n",
    "    dataset_SortYourMusic.reset_index(inplace=True)\n",
    "    \n",
    "    EDA_songs = dataset_Silkey.merge(dataset_SortYourMusic, on=\"index\")\n",
    "    \n",
    "    # Select relevant features\n",
    "    EDA_songs_cleaned1 = EDA_songs.drop(columns=[\"albumName\", \n",
    "                                    \"trackNumber\",\n",
    "                                    \"addedBy\",\n",
    "                                    \"albumArtistsNames\",\n",
    "                                    \"trackUrl\",\n",
    "                                    \"artistUrl\",\n",
    "                                    \"albumUrl\",\n",
    "                                    \"trackIsrc\",\n",
    "                                    \"albumUpc\",\n",
    "                                    \"albumType\",\n",
    "                                    \"albumPopularity\",\n",
    "                                    'Title', \n",
    "                                    'Artist', \n",
    "                                    'Release', \n",
    "                                    \"Length\", \n",
    "                                    \"Pop.\",\n",
    "                                    \"RND\",\n",
    "                                    '#',          \n",
    "                                    ], axis=0)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    #EDA_songs_cleaned2 = EDA_songs_cleaned1.drop_duplicates(subset=[\"artistName\", \"trackName\"], keep=\"first\")\n",
    "    \n",
    "    # Drop NaN\n",
    "    # Remove all local data -> there is no information about this data that can be used for further analysis\n",
    "    EDA_songs_cleaned2 = EDA_songs_cleaned1[EDA_songs_cleaned1[\"isLocal\"]==\"stream\"]\n",
    "    \n",
    "    \n",
    "    # Split Genre column \n",
    "    EDA_songs_cleaned2_Genres = EDA_songs_cleaned2[\"artistGenres\"].str.split(\",\", expand=True)\n",
    "    # Leave only first column\n",
    "    EDA_songs_cleaned2_Genres_reduced = EDA_songs_cleaned2_Genres.iloc[:,0:5]\n",
    "    # Rename columns\n",
    "    EDA_songs_cleaned2_Genres_reduced.rename(columns={0:\"Genre1\",\n",
    "                                                    1:\"Genre2\",\n",
    "                                                    2:\"Genre3\",\n",
    "                                                    3:\"Genre4\",\n",
    "                                                    4:\"Genre5\"}, inplace=True)\n",
    "    \n",
    "    # Merge \"Genre\"-DataFrame with the initial dataset\n",
    "    EDA_songs_cleaned2_Genres_reduced.reset_index(inplace=True)\n",
    "    EDA_songs_cleaned3 = EDA_songs_cleaned2.merge(EDA_songs_cleaned2_Genres_reduced, on=\"index\")\n",
    "    \n",
    "    \n",
    "    #Drop columns\n",
    "    EDA_songs_cleaned3.drop(columns=[\"isLocal\", \"artistGenres\",\"index\"], inplace=True)\n",
    "    \n",
    "    # change data type to datetime: \n",
    "    EDA_songs_cleaned3[\"addedAt\"] = pd.to_datetime(EDA_songs_cleaned3[\"addedAt\"]).dt.tz_convert(None)\n",
    "    EDA_songs_cleaned3[\"albumReleaseDate\"] = pd.to_datetime(EDA_songs_cleaned3[\"albumReleaseDate\"], yearfirst=True)\n",
    "    #EDA_songs_cleaned3[\"trackDuration\"] = pd.to_datetime(EDA_songs_cleaned3[\"trackDuration\"])\n",
    "    \n",
    "    return EDA_songs_cleaned3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) AfroHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AfroHouse = prepare_EDA(\"AfroHouse\")\n",
    "AfroHouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AfroHouse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AfroHouse.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_AfroHouse.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Hip Hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HipHop = prepare_EDA(\"HipHop\")\n",
    "HipHop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HipHop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HipHop.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_HipHop.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Hip Hop Oldschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HipHopOldschool = prepare_EDA(\"HipHopOldschool\")\n",
    "HipHopOldschool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HipHopOldschool.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HipHopOldschool.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_HipHopOldschool.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Afrobeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeats = prepare_EDA(\"Afrobeats\")\n",
    "Afrobeats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeats.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Afrobeats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Afro beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeat_AfricanClassics = prepare_EDA(\"Afrobeat_AfricanClassics\")\n",
    "Afrobeat_AfricanClassics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeat_AfricanClassics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afrobeat_AfricanClassics.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Afrobeat_AfricanClassics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Kuduro & Naija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kuduro = prepare_EDA(\"KuduroNaija\")\n",
    "Kuduro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kuduro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kuduro.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Kuduro.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) SA Sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_sounds = prepare_EDA(\"SAsounds_Amapiano_Gqom\")\n",
    "SA_sounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_sounds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_sounds.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_SA_sounds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Roots Reggae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roots = prepare_EDA(\"RootsReggae\")\n",
    "Roots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roots.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Roots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Modern Roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModernRoots = prepare_EDA(\"ModernRoots\")\n",
    "ModernRoots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModernRoots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModernRoots.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_ModernRoots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Dancehall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dancehall = prepare_EDA(\"Dancehall\")\n",
    "Dancehall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dancehall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dancehall.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Dancehall.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Dub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dub = prepare_EDA(\"Dub\")\n",
    "Dub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dub.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Dub.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock = prepare_EDA(\"Rock_Indie\")\n",
    "Rock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Rock.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m) Jazz (instrumental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jazz_inst = prepare_EDA(\"Jazz_instrumental\")\n",
    "Jazz_inst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jazz_inst.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jazz_inst.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_Jazz_inst.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n) Deep House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepHouse = prepare_EDA(\"DeepHouse\")\n",
    "DeepHouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepHouse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepHouse.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_DeepHouse.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o) Groovy House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroovyHouse = prepare_EDA(\"GroovyHouse\")\n",
    "GroovyHouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroovyHouse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroovyHouse.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_GroovyHouse.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p) Funk & Soul & Disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FunkSoulDisco = prepare_EDA(\"FunkSoulDisco\")\n",
    "FunkSoulDisco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FunkSoulDisco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FunkSoulDisco.to_csv(\"C:/Users/Agnieszka/Downloads/Datasets/Music/MyDatasets/EDA_FunkSoulDisco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
